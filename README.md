# CoVShorts-News-Summarization-Application-Based-on-Deep-NLP-Transformers-for-SARS-CoV-2
Amidst the grueling SARS-CoV-2 pandemic which has affected the lives of people across the world, the accelerating growth in COVID-19 related news articles is making it difficult for the general public to stay up-to-date with all the information. News articles are a crucial medium to convey coronavirus-related information across the world to the public. Short summaries of news articles can assist the public in grasping a gist of an entire article without having to read it fully. With the evolution of Deep Learning in Natural Language Processing (NLP), we exploited the power of recent advances in pre-trained and transformer-based NLP models to perform text summarization over the COVID-19 Public Media Dataset. For this, we analyzed and compared the results of BERT, GPT-2, XLNet, BART, and T5. The first three models are among the most popular extractive summarization models and the last two are abstractive summarization models. We evaluated the results of our experiments using ROUGE scores (ROUGE-2 and ROUGE-L) and found that BERT, a transformer autoencoder, outperforms the other models under consideration in SARS-CoV-2 news summarization. Thus, we leveraged BERT in our web application “CoVShorts” to summarize COVID-19 articles. Further, we visually analyzed the dataset to depict the most used words in COVID-19 news articles using Word Cloud to validate the accuracy of the summarization task. CoVShorts will serve the public by helping them in gaining brief, concise, and to-the-point summaries quickly.
